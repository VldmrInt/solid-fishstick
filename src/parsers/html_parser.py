"""
–ü–∞—Ä—Å–µ—Ä –º–∞–≥–∞–∑–∏–Ω–∞ Ozon —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π HTML –ø–∞—Ä—Å–∏–Ω–≥
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç undetected-chromedriver –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
"""

import re
import json
import time
import random
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from pathlib import Path

from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException

try:
    from undetected_chromedriver import Chrome, ChromeOptions
    HAS_UC = True
except ImportError:
    HAS_UC = False
    Chrome = None
    ChromeOptions = None

try:
    from bs4 import BeautifulSoup
    HAS_BS4 = True
except ImportError:
    HAS_BS4 = False

from src.config.settings import Settings

logger = logging.getLogger(__name__)


@dataclass
class ProductInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–≤–∞—Ä–µ"""
    sku: str
    name: str
    current_price: str
    original_price: str
    link: str
    image_url: str = ''
    rating: str = ''
    reviews_count: str = ''
    seller_name: str = ''
    seller_inn: str = ''
    category: str = ''
    brand: str = ''
    success: bool = True
    error: str = ''

    def to_dict(self) -> dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return asdict(self)


class OzonHTMLParser:
    """
    –ü–∞—Ä—Å–µ—Ä –º–∞–≥–∞–∑–∏–Ω–∞ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π HTML –ø–∞—Ä—Å–∏–Ω–≥.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç undetected-chromedriver –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü
    –∏ BeautifulSoup –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.
    """

    # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
    RE_PRODUCT_ID = re.compile(r'/product/[^\"\'>]*-(\d+)', re.IGNORECASE)
    RE_PRICE = re.compile(r'[\d\u00A0\u2009\u202F]+(?:\u2009| )?‚ÇΩ')
    RE_SKU = re.compile(r'\"sku\"\s*:\s*(\d+)')

    def __init__(self, seller_url: str, headless: bool = True):
        """
        Args:
            seller_url: URL –º–∞–≥–∞–∑–∏–Ω–∞
            headless: –ó–∞–ø—É—Å–∫–∞—Ç—å –≤ headless —Ä–µ–∂–∏–º–µ
        """
        if not HAS_UC:
            raise ImportError(
                "undetected-chromedriver –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install undetected-chromedriver"
            )

        self.seller_url = seller_url
        self.seller_id = Settings.get_seller_id(seller_url)
        self.headless = headless
        self.driver: Optional[Chrome] = None
        self.products: List[ProductInfo] = []

        if not self.seller_id:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –ø—Ä–æ–¥–∞–≤—Ü–∞ –∏–∑ URL: {seller_url}")

    def _create_driver(self) -> Chrome:
        """–°–æ–∑–¥–∞–µ—Ç undetected Chrome driver"""
        options = ChromeOptions()

        if self.headless:
            options.add_argument("--headless=new")

        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-notifications")
        options.add_argument("--disable-gpu")
        options.add_argument("--log-level=3")
        options.add_argument(
            "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36"
        )
        options.add_experimental_option("prefs", {
            "profile.default_content_setting_values.notifications": 2
        })
        options.add_argument("--disable-blink-features=AutomationControlled")

        driver = Chrome(options=options, version_main=Settings.CHROME_VERSION)
        logger.info(f"–°–æ–∑–¥–∞–Ω undetected-chromedriver (headless={self.headless})")
        return driver

    def parse_all_pages(self, max_pages: int = 100) -> List[ProductInfo]:
        """
        –ü–∞—Ä—Å–∏—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞–≥–∞–∑–∏–Ω–∞.

        Args:
            max_pages: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü

        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
        """
        logger.info(f"–ù–∞—á–∞–ª–æ HTML –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–∞–≥–∞–∑–∏–Ω–∞: {self.seller_url}")
        logger.info(f"ID –ø—Ä–æ–¥–∞–≤—Ü–∞: {self.seller_id}")
        logger.info(f"–†–µ–∂–∏–º: {'headless' if self.headless else '—Å –≤–∏–¥–∏–º—ã–º –æ–∫–Ω–æ–º'}")

        try:
            self.driver = self._create_driver()

            page_num = 1
            empty_pages_count = 0
            max_empty_pages = 3

            while page_num <= max_pages:
                logger.info(f"üìÑ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}/{max_pages}...")

                try:
                    page_products = self._parse_page(page_num)

                    if not page_products:
                        empty_pages_count += 1
                        logger.warning(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –ø—É—Å—Ç–∞—è ({empty_pages_count}/{max_empty_pages})")

                        if empty_pages_count >= max_empty_pages:
                            logger.info("–î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü, –∑–∞–≤–µ—Ä—à–∞–µ–º")
                            break
                    else:
                        empty_pages_count = 0
                        self.products.extend(page_products)
                        logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–∞–π–¥–µ–Ω–æ {len(page_products)} —Ç–æ–≤–∞—Ä–æ–≤")

                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                    delay = random.uniform(Settings.REQUEST_DELAY_MIN, Settings.REQUEST_DELAY_MAX)
                    logger.debug(f"–ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π: {delay:.1f} —Å–µ–∫")
                    time.sleep(delay)

                    page_num += 1

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                    break

            logger.info(f"HTML –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(self.products)}")
            return self.products

        finally:
            if self.driver:
                self.driver.quit()
                logger.info("WebDriver –∑–∞–∫—Ä—ã—Ç")

    def _parse_page(self, page_num: int) -> List[ProductInfo]:
        """
        –ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É.

        Args:
            page_num: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL
        current_url = f"{self.seller_url}&page={page_num}" if page_num > 1 else self.seller_url

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        self.driver.get(current_url)
        logger.debug(f"–û—Ç–∫—Ä—ã—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {current_url}")

        # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏
        time.sleep(5)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —ç–∫—Ä–∞–Ω –ø—Ä–æ–≤–µ—Ä–∫–∏ CloudFlare
        try:
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located(
                    (By.XPATH, "//*[contains(text(), '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–∂–¥–∏—Ç–µ—Å—å –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏')]")
                )
            )
            logger.info("üîí –û–±–Ω–∞—Ä—É–∂–µ–Ω —ç–∫—Ä–∞–Ω –ø—Ä–æ–≤–µ—Ä–∫–∏ CloudFlare, –∂–¥–µ–º...")
            WebDriverWait(self.driver, 60).until_not(
                EC.presence_of_element_located(
                    (By.XPATH, "//*[contains(text(), '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–∂–¥–∏—Ç–µ—Å—å –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏')]")
                )
            )
            logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ CloudFlare –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        except TimeoutException:
            logger.debug("–≠–∫—Ä–∞–Ω –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        try:
            WebDriverWait(self.driver, 5).until(
                EC.presence_of_element_located(
                    (By.XPATH, "//*[contains(text(), '–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å')]")
                )
            )
            logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –ø—É—Å—Ç–∞—è (–Ω–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤)")
            return []
        except TimeoutException:
            pass  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ç–æ–≤–∞—Ä–∞–º–∏

        # –°–∫—Ä–æ–ª–ª–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
        self._scroll_page()

        # –ü–æ–ª—É—á–∞–µ–º HTML
        page_source = self.driver.page_source

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if page_num == 1:
            debug_file = Settings.PROJECT_ROOT / f'debug_html_page_{page_num}.html'
            try:
                with open(debug_file, 'w', encoding='utf-8') as f:
                    f.write(page_source)
                logger.info(f"üíæ HTML –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {debug_file} –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å debug HTML: {e}")

        # –ü–∞—Ä—Å–∏–º HTML
        if HAS_BS4:
            products = self._parse_html_with_bs4(page_source)
        else:
            products = self._parse_html_fallback(page_source)

        return products

    def _scroll_page(self):
        """–°–∫—Ä–æ–ª–ª–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        last_height = self.driver.execute_script("return document.body.scrollHeight")
        no_change_count = 0
        max_no_change = 5
        max_attempts = 20
        scroll_attempts = 0

        while scroll_attempts < max_attempts:
            scroll_step = random.randint(500, 1500)
            self.driver.execute_script(f"window.scrollBy(0, {scroll_step});")
            time.sleep(random.uniform(1, 2))

            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                no_change_count += 1
                if no_change_count >= max_no_change:
                    break
            else:
                no_change_count = 0

            last_height = new_height
            scroll_attempts += 1

        logger.debug(f"–°–∫—Ä–æ–ª–ª –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {scroll_attempts} –ø–æ–ø—ã—Ç–æ–∫")

    def _parse_html_with_bs4(self, html: str) -> List[ProductInfo]:
        """–ü–∞—Ä—Å–∏—Ç HTML —Å –ø–æ–º–æ—â—å—é BeautifulSoup"""
        soup = BeautifulSoup(html, 'html.parser')
        items = {}

        # –ü–æ–∏—Å–∫ –ø–æ —Å—Å—ã–ª–∫–∞–º –Ω–∞ —Ç–æ–≤–∞—Ä—ã
        for a in soup.find_all('a', href=True):
            href = a['href']
            m = self.RE_PRODUCT_ID.search(href)
            if not m:
                continue

            pid = m.group(1)

            # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            name = self._clean_text(a.text)
            if not name:
                img = a.find('img')
                if img and 'alt' in img.attrs:
                    name = self._clean_text(img['alt'])

            # –ü–æ–∏—Å–∫ —Ü–µ–Ω –≤ —Ä–æ–¥–∏—Ç–µ–ª—è—Ö
            prices = []
            container = a.parent
            for _ in range(4):
                if container:
                    text = container.get_text(separator=' ', strip=True)
                    found_prices = self.RE_PRICE.findall(text)
                    for p in found_prices:
                        cleaned_p = self._clean_text(p)
                        if cleaned_p and cleaned_p not in prices:
                            prices.append(cleaned_p)
                    container = container.parent

            # –ü–æ–ª–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
            full_link = f"https://www.ozon.ru{href}" if not href.startswith('http') else href

            items[pid] = {
                'name': name,
                'sku': pid,
                'prices': prices[:2],
                'link': full_link
            }

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ ProductInfo
        products = []
        for pid, data in items.items():
            prices = data['prices']
            product = ProductInfo(
                sku=data['sku'],
                name=data['name'],
                current_price=prices[0] if len(prices) > 0 else '',
                original_price=prices[1] if len(prices) > 1 else '',
                link=data['link']
            )
            products.append(product)

        logger.debug(f"BeautifulSoup: –Ω–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        return products

    def _parse_html_fallback(self, html: str) -> List[ProductInfo]:
        """–ü–∞—Ä—Å–∏—Ç HTML —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π (fallback)"""
        items = {}

        for m in self.RE_PRODUCT_ID.finditer(html):
            pid = m.group(1)
            start, end = m.start(), m.end()
            window = html[max(0, start - 2000): end + 2000]

            # –ù–∞–∑–≤–∞–Ω–∏–µ
            name_match = (
                re.search(r'alt=\"([^\"]{5,300}?)\"', window) or
                re.search(r'title=\"([^\"]{5,300}?)\"', window)
            )
            name = self._clean_text(name_match.group(1)) if name_match else ''

            # –¶–µ–Ω—ã
            prices = [self._clean_text(p) for p in self.RE_PRICE.findall(window)]
            seen = set()
            prices = [p for p in prices if p and p not in seen and not seen.add(p)][:2]

            # –°—Å—ã–ª–∫–∞
            link = f"https://www.ozon.ru/product/-{pid}/"

            items[pid] = {
                'name': name,
                'sku': pid,
                'prices': prices,
                'link': link
            }

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ ProductInfo
        products = []
        for pid, data in items.items():
            prices = data['prices']
            product = ProductInfo(
                sku=data['sku'],
                name=data['name'],
                current_price=prices[0] if len(prices) > 0 else '',
                original_price=prices[1] if len(prices) > 1 else '',
                link=data['link']
            )
            products.append(product)

        logger.debug(f"Fallback: –Ω–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        return products

    @staticmethod
    def _clean_text(s: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not s:
            return ''
        s = s.strip()
        s = re.sub(r'[\u00A0\u2009\u202F]+', ' ', s)
        s = re.sub(r'\s+', ' ', s)
        return s

    def get_products(self) -> List[ProductInfo]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        return self.products

    def get_products_count(self) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        return len(self.products)
